{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习报告二：回归模型\n",
    "- 姓名：李欣\n",
    "- 学号：2011165\n",
    "- 专业：计算机科学与技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 实验要求\n",
    "题目：回归模型\n",
    "\n",
    "* 回归是监督学习的一个重要问题，回归用于预测输入变量和输出变量之间的关系，特别是当输入变量的值发生变化时，输出变量的值也随之发生变化。\n",
    "* 回归模型是一种表示从输入变量到输出变量之间映射的函数\n",
    "* 对连续值的预测\n",
    "* 可以用合适的曲线揭示样本点随着自变量的变化关系\n",
    "实验条件：给定winequality-white.csv数据集\n",
    "\n",
    "实验要求：\n",
    "1. 基本要求：\n",
    "构建线性回归模型，学习使用批量梯度下降和随机梯度下降进行优化，并进行一定的分析。\n",
    "2. 中级要求：\n",
    "探究回归模型在机器学习和统计学上的差异。\n",
    "3. 提高要求：\n",
    "编程实现岭回归算法，求解训练样本的岭回归模型，平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法均可）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pandas\n",
    "import pandas as pd\n",
    "# 导入numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原数据集大小: 4898\n",
      "去重后保留重复值数据集大小: 3961\n",
      "去重后不保留重复值数据集大小: 3189\n"
     ]
    }
   ],
   "source": [
    "# 使用pd.read_csv函数读入csv文件\n",
    "data = pd.read_csv(\"winequality-white.csv\")\n",
    "# 显示date文件的前五行和后五行\n",
    "# data.head(5)\n",
    "# data.tail(5)\n",
    "test_data=data\n",
    "test_data1=data\n",
    "print(\"原数据集大小:\",test_data.shape[0])\n",
    "test_data=test_data.drop_duplicates() # 包含重复值\n",
    "print(\"去重后保留重复值数据集大小:\",test_data.shape[0])\n",
    "test_data1=test_data1.drop_duplicates(keep=False) # 包含重复值\n",
    "print(\"去重后不保留重复值数据集大小:\",test_data1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现原数据集中有不少重复的数据（行），对回归系数与mse损失函数可能会产生影响。在本次实验中我们没有考虑去重问题，在后期会进行可能的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理的几种方法\n",
    "# np.mean(x, 0)计算每一列的均值\n",
    "# np.max(x, 0)计算每一列的最大值\n",
    "# np.min(x, 0)计算每一列的最小值\n",
    "\n",
    "def Zero_c_N(x):\n",
    "    return (x - np.mean(x, 0)) / (np.max(x, 0) - np.min(x, 0))\n",
    "\n",
    "def Normalization(x):\n",
    "    x = (x - np.min(x, 0)) / (np.max(x, 0) - np.min(x, 0))\n",
    "    return x\n",
    "\n",
    "def Standardization(x):\n",
    "    return (x - np.mean(x, 0)) / np.std(x, 0)\n",
    "\n",
    "# 提取特征和标签\n",
    "# 所有行的0到最后第二列的数据，为特征\n",
    "X = data.iloc[:, 0:-1]  #\n",
    "X = Standardization(X)\n",
    "#所有行的最后一列的数据为标签\n",
    "Y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过实验测试，使用Standardization的效果最好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  83.,  931., 1440., 1402.,  623.,  235.,  134.,   26.,   20.,\n",
       "           4.]),\n",
       " array([-2.36470935, -1.61107823, -0.85744711, -0.10381598,  0.64981514,\n",
       "         1.40344626,  2.15707739,  2.91070851,  3.66433963,  4.41797076,\n",
       "         5.17160188]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化中心化后的sulphates特征\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(X[\"sulphates\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172097</td>\n",
       "      <td>-0.081770</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>2.821349</td>\n",
       "      <td>-0.035355</td>\n",
       "      <td>0.569932</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>2.331512</td>\n",
       "      <td>-1.246921</td>\n",
       "      <td>-0.349184</td>\n",
       "      <td>-1.393152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.657501</td>\n",
       "      <td>0.215896</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>0.147747</td>\n",
       "      <td>-1.253019</td>\n",
       "      <td>-0.149685</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.740029</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>-0.824276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.475751</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.543838</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>0.193523</td>\n",
       "      <td>-0.312141</td>\n",
       "      <td>-0.973336</td>\n",
       "      <td>0.358665</td>\n",
       "      <td>0.475102</td>\n",
       "      <td>-0.436816</td>\n",
       "      <td>-0.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.117278</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.687541</td>\n",
       "      <td>1.121091</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.499203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.117278</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.687541</td>\n",
       "      <td>1.121091</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.499203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.776015</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>-0.365197</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>-0.310008</td>\n",
       "      <td>-0.664970</td>\n",
       "      <td>-1.091000</td>\n",
       "      <td>-0.965483</td>\n",
       "      <td>0.541334</td>\n",
       "      <td>0.088973</td>\n",
       "      <td>0.557282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.301959</td>\n",
       "      <td>0.414339</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>0.317179</td>\n",
       "      <td>0.056196</td>\n",
       "      <td>1.275590</td>\n",
       "      <td>0.697499</td>\n",
       "      <td>0.291789</td>\n",
       "      <td>-0.253446</td>\n",
       "      <td>-0.261553</td>\n",
       "      <td>-0.743008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.420473</td>\n",
       "      <td>-0.379435</td>\n",
       "      <td>-1.191592</td>\n",
       "      <td>-1.023637</td>\n",
       "      <td>-0.218457</td>\n",
       "      <td>-0.312141</td>\n",
       "      <td>-0.643875</td>\n",
       "      <td>-0.497350</td>\n",
       "      <td>-1.313153</td>\n",
       "      <td>-0.261553</td>\n",
       "      <td>-0.905544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.605613</td>\n",
       "      <td>0.116674</td>\n",
       "      <td>-0.282557</td>\n",
       "      <td>-1.043355</td>\n",
       "      <td>-1.088192</td>\n",
       "      <td>-0.900190</td>\n",
       "      <td>-0.667408</td>\n",
       "      <td>-1.784717</td>\n",
       "      <td>1.004955</td>\n",
       "      <td>-0.962605</td>\n",
       "      <td>1.857572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.013043</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>0.378559</td>\n",
       "      <td>-1.102508</td>\n",
       "      <td>-1.179743</td>\n",
       "      <td>-0.782580</td>\n",
       "      <td>-0.949803</td>\n",
       "      <td>-1.543962</td>\n",
       "      <td>0.475102</td>\n",
       "      <td>-1.488394</td>\n",
       "      <td>1.044891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     1.0       0.172097         -0.081770     0.213280        2.821349   \n",
       "1     1.0      -0.657501          0.215896     0.048001       -0.944765   \n",
       "2     1.0       1.475751          0.017452     0.543838        0.100282   \n",
       "3     1.0       0.409125         -0.478657    -0.117278        0.415768   \n",
       "4     1.0       0.409125         -0.478657    -0.117278        0.415768   \n",
       "...   ...            ...               ...          ...             ...   \n",
       "4893  1.0      -0.776015         -0.677101    -0.365197       -0.944765   \n",
       "4894  1.0      -0.301959          0.414339     0.213280        0.317179   \n",
       "4895  1.0      -0.420473         -0.379435    -1.191592       -1.023637   \n",
       "4896  1.0      -1.605613          0.116674    -0.282557       -1.043355   \n",
       "4897  1.0      -1.013043         -0.677101     0.378559       -1.102508   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide   density  \\\n",
       "0     -0.035355             0.569932              0.744565  2.331512   \n",
       "1      0.147747            -1.253019             -0.149685 -0.009154   \n",
       "2      0.193523            -0.312141             -0.973336  0.358665   \n",
       "3      0.559727             0.687541              1.121091  0.525855   \n",
       "4      0.559727             0.687541              1.121091  0.525855   \n",
       "...         ...                  ...                   ...       ...   \n",
       "4893  -0.310008            -0.664970             -1.091000 -0.965483   \n",
       "4894   0.056196             1.275590              0.697499  0.291789   \n",
       "4895  -0.218457            -0.312141             -0.643875 -0.497350   \n",
       "4896  -1.088192            -0.900190             -0.667408 -1.784717   \n",
       "4897  -1.179743            -0.782580             -0.949803 -1.543962   \n",
       "\n",
       "            pH  sulphates   alcohol  \n",
       "0    -1.246921  -0.349184 -1.393152  \n",
       "1     0.740029   0.001342 -0.824276  \n",
       "2     0.475102  -0.436816 -0.336667  \n",
       "3     0.011480  -0.787342 -0.499203  \n",
       "4     0.011480  -0.787342 -0.499203  \n",
       "...        ...        ...       ...  \n",
       "4893  0.541334   0.088973  0.557282  \n",
       "4894 -0.253446  -0.261553 -0.743008  \n",
       "4895 -1.313153  -0.261553 -0.905544  \n",
       "4896  1.004955  -0.962605  1.857572  \n",
       "4897  0.475102  -1.488394  1.044891  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里注意一个小trick：回归系数会比特征x多一维，为了向量相乘方便，可以在训练集X左侧添加全为1的一列\n",
    "# concat函数用于拼接\n",
    "# shape[0]获取行数\n",
    "# anxis=1 按列拼接\n",
    "# pd.DataFrame(np.ones(X.shape[0]), columns=['x0']) 左边是一列名为x0且元素全为1的列\n",
    "# X 右边是X\n",
    "data0 = pd.concat([pd.DataFrame(np.ones(X.shape[0]), columns=['x0']), X], axis=1)\n",
    "data0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 一、基本要求\n",
    "\n",
    "具体要求：\n",
    "\n",
    "将数据集winequality-white.csv按照4:1划分为训练集和测试集。\n",
    "\n",
    "1. 构造线性回归模型，并采用批量梯度下降和随机梯度下降进行优化；输出训练集和测试集的均方误差（MSE），画出MSE收敛曲线。\n",
    "\n",
    "2. 对于批量梯度下降和随机梯度下降，采用不同的学习率并进行MSE曲线展示，分析选择最佳的学习率。\n",
    " \n",
    "特别需要注意：\n",
    "\n",
    "* 划分数据集时尽可能保持数据分布的一致性，保持样本类别比例相似，可采用分层采样的方式。\n",
    "\n",
    "* 需要对数据集进行一定的预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (一)步骤一：将数据集按照4:1划分为训练集和测试集(应选用方法2：按照标签重新划分数据集)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 1、不能满足该实验要求，但有点道理的划分数据集，在不是分类的情况下可能可以选取的划分方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机排列函数np.random.permutation将索引随机打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1818,  133,  288, ..., 3511,  865, 1032])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将索引随机打乱\n",
    "row_indices=np.random.permutation(data0.shape[0])\n",
    "# 查看打乱后的索引\n",
    "row_indices\n",
    "# # 将拼接过后的特征矩阵/分类结果 按照4:1的比例划分，训练集的个数\n",
    "num=int((row_indices.shape[0])*0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的大小为: 3918\n"
     ]
    }
   ],
   "source": [
    "# 创建训练集\n",
    "# row_indices[0:num]\n",
    "x_train=data0.iloc[row_indices[0:num],:]\n",
    "y_train=Y.iloc[row_indices[0:num]]\n",
    "# 训练集的个数\n",
    "print(\"训练集的大小为:\",x_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集的大小为: 980\n"
     ]
    }
   ],
   "source": [
    "# 创建测试集\n",
    "# row_indices[num:]\n",
    "x_test=data0.iloc[row_indices[num:],:]\n",
    "y_test=Y.iloc[row_indices[num:]]\n",
    "# 测试集的个数\n",
    "print(\"测试集的大小为:\",x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*注意！！！*\n",
    "如上创建测试集似乎由一些问题，和同学交流过后我认识到，quality为分类结果label，因为训练结果为几个label(3-9)，极端情况下，存在某一label都被训练到或某一label完全没有训练到。\n",
    "\n",
    "显然，训练和测试结果很有可能出现较大的偏差。故，应将每一类别的数据划分训练集和测试集\n",
    "\n",
    "此外，应该看一看原数据集中是否有相同的行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2、按照分类结果，即标签重新划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172097</td>\n",
       "      <td>-0.081770</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>2.821349</td>\n",
       "      <td>-0.035355</td>\n",
       "      <td>0.569932</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>2.331512</td>\n",
       "      <td>-1.246921</td>\n",
       "      <td>-0.349184</td>\n",
       "      <td>-1.393152</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.657501</td>\n",
       "      <td>0.215896</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>0.147747</td>\n",
       "      <td>-1.253019</td>\n",
       "      <td>-0.149685</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.740029</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>-0.824276</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.475751</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.543838</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>0.193523</td>\n",
       "      <td>-0.312141</td>\n",
       "      <td>-0.973336</td>\n",
       "      <td>0.358665</td>\n",
       "      <td>0.475102</td>\n",
       "      <td>-0.436816</td>\n",
       "      <td>-0.336667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.117278</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.687541</td>\n",
       "      <td>1.121091</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.499203</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.117278</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.687541</td>\n",
       "      <td>1.121091</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.499203</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.172097         -0.081770     0.213280        2.821349  -0.035355   \n",
       "1      -0.657501          0.215896     0.048001       -0.944765   0.147747   \n",
       "2       1.475751          0.017452     0.543838        0.100282   0.193523   \n",
       "3       0.409125         -0.478657    -0.117278        0.415768   0.559727   \n",
       "4       0.409125         -0.478657    -0.117278        0.415768   0.559727   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.569932              0.744565  2.331512 -1.246921  -0.349184   \n",
       "1            -1.253019             -0.149685 -0.009154  0.740029   0.001342   \n",
       "2            -0.312141             -0.973336  0.358665  0.475102  -0.436816   \n",
       "3             0.687541              1.121091  0.525855  0.011480  -0.787342   \n",
       "4             0.687541              1.121091  0.525855  0.011480  -0.787342   \n",
       "\n",
       "    alcohol  quality  \n",
       "0 -1.393152        6  \n",
       "1 -0.824276        6  \n",
       "2 -0.336667        6  \n",
       "3 -0.499203        6  \n",
       "4 -0.499203        6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上述方法不行！重新切分数据\n",
    "data0=pd.concat([X,Y],axis=1)\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分层随机选取训练样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分层 随机 选取训练样本\n",
    "def sample_split(data, train_ratio=0.8, label='quality', seed=None):\n",
    "    xy_test=None\n",
    "    # 根据分类标签分组\n",
    "    xy_train = data.groupby(label).apply(lambda x: x.sample(frac=train_ratio, random_state=seed))\n",
    "    \n",
    "    # 将xy_train每行索引存入列表，为了找到在data中对应的行，删除得到test数据集\n",
    "    list_index=[]\n",
    "    for i in range(0,xy_train.shape[0]):\n",
    "        list_index.append((xy_train.iloc[i].name)[1])\n",
    "    xy_test=np.delete(data.values,list_index,axis=0)\n",
    "    \n",
    "    # 将训练集打乱顺序\n",
    "    xy_train = xy_train.sample(frac=1, random_state=seed)\n",
    "    xy_train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return xy_train, xy_test\n",
    "\n",
    "# 训练集和测试集\n",
    "type(data0)\n",
    "train, test = sample_split(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小: 4898\n",
      "训练集大小(80%): 3918\n",
      "测试集大小(20%): 980\n"
     ]
    }
   ],
   "source": [
    "print(\"数据集大小:\",data0.shape[0])\n",
    "print(\"训练集大小(80%):\",train.shape[0])\n",
    "print(\"测试集大小(20%):\",test.shape[0])\n",
    "test=pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集测试与标签分离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取特征和标签\n",
    "x_temp= train.iloc[:,:-1]\n",
    "y=train.iloc[:, -1]\n",
    "\n",
    "# 这里注意一个小trick：回归系数会比特征x多一维，为了向量相乘方便，可以在训练集X左侧添加全为1的一列\n",
    "x_final = pd.concat([pd.DataFrame(np.ones(x_temp.shape[0]), columns=['x0']), x_temp], axis=1)\n",
    "size, feature_num = x_final.shape\n",
    "\n",
    "# 便于后续计算，将特征矩阵和分类结果都由dataframe转换为二维ndarray：\n",
    "x_train= x_final.values\n",
    "y_train = y.values.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集特征与分类标签分离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.iloc[:,:-1]\n",
    "y = test.iloc[:, -1]\n",
    "x = pd.concat([pd.DataFrame(np.ones(x.shape[0]), columns=['x0']), x], axis=1)\n",
    "test_x = x.values\n",
    "test_y = y.values.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此划分好了训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (二)步骤二：线性回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义损失函数mse："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(x,y,theta):\n",
    "    return np.mean((x@theta-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 批量梯度下降："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gd(x, y, theta, learning_ratio=0.01, max_iter=10000, change_ratio=1e-4, n_unchange=5):\n",
    "    n_iter = 0\n",
    "    no_change = 0\n",
    "    mses = []\n",
    "    random_mse=compute_mse(x,y,theta)\n",
    "    mses.append(random_mse)\n",
    "    # 停止条件：\n",
    "    # 1.到达最大迭代次数\n",
    "    # 2.边化率太小\n",
    "    while n_iter < max_iter:\n",
    "        n_iter += 1\n",
    "        theta = learning_ratio/size * x.T@(y - x@theta) + theta \n",
    "        mse_temp = compute_mse(x,y,theta)\n",
    "        if abs(mse_temp - mses[-1]) < change_ratio:\n",
    "            no_change += 1\n",
    "            if no_change >= n_unchange:\n",
    "                break\n",
    "        else:\n",
    "            no_change = 0\n",
    "        mses.append(mse_temp)\n",
    "    return theta, mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30809531, 0.36605552, 0.13846   , 0.18538677, 0.99626649,\n",
       "       0.13420059, 0.23141642, 0.25913349, 0.98135508, 0.87390355,\n",
       "       0.66953199, 0.27299143])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化回归系数\n",
    "W_init = np.random.rand(feature_num, 1)\n",
    "W_init.reshape(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批量梯度下降训练集mse： 0.5686416292571671\n"
     ]
    }
   ],
   "source": [
    "w_gd, mses_gd = fit_gd(x_train,y_train,W_init, learning_ratio=0.01, max_iter=1000, change_ratio=1e-19, n_unchange=5)\n",
    "# mses_gd\n",
    "print(\"批量梯度下降训练集mse：\",mses_gd[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sgd(x, y, theta, learning_ratio=0.01, max_iter=10000, change_ratio=1e-6, n_unchange=5):\n",
    "    n_iter = 0\n",
    "    no_change = 0\n",
    "    mses = []\n",
    "    random_mse=compute_mse(x,y,theta)\n",
    "    mses.append(random_mse)\n",
    "    while n_iter < max_iter:\n",
    "        n_iter += 1\n",
    "        i = np.random.randint(size)\n",
    "        tmp = (y[i] - x[i]@theta)\n",
    "        theta = learning_ratio * x[i].reshape(feature_num,1)*tmp + theta\n",
    "        mse_temp = compute_mse(x,y,theta)\n",
    "        if abs(mse_temp - mses[-1]) < change_ratio:\n",
    "            no_change += 1\n",
    "            if no_change >= n_unchange:\n",
    "                break\n",
    "        else:\n",
    "            no_change = 0\n",
    "        mses.append(mse_temp)\n",
    "    return theta, mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机梯度下降训练集mse： 0.5814792570672931\n"
     ]
    }
   ],
   "source": [
    "w_sgd, mses_sgd = fit_sgd(x_train,y_train,W_init, learning_ratio=0.01, max_iter=1000, change_ratio=1e-4, n_unchange=5)\n",
    "print(\"随机梯度下降训练集mse：\",mses_sgd[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### (三)步骤三：训练集和测试集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批量梯度下降训练集mse： 0.5686416292571671\n",
      "批量梯度下降测试集mse： 0.5682573628607406\n",
      "随机梯度下降训练集mse： 0.5814792570672931\n",
      "随机梯度下降测试集mse： 0.5870369253924073\n"
     ]
    }
   ],
   "source": [
    "print(\"批量梯度下降训练集mse：\",mses_gd[-1])\n",
    "print(\"批量梯度下降测试集mse：\",compute_mse(test_x,test_y,w_gd))\n",
    "\n",
    "print(\"随机梯度下降训练集mse：\",mses_sgd[-1])\n",
    "print(\"随机梯度下降测试集mse：\",compute_mse(test_x,test_y,w_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (四)步骤四：绘制mse收敛曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ef7323fa0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ef7332310>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'n_iters')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'mse with different n_iters')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots()\n",
    "axes.plot(np.arange(len(mses_gd)), mses_gd, 'r')\n",
    "axes.plot(np.arange(len(mses_sgd)), mses_sgd, 'b')\n",
    "axes.set_xlabel('n_iters')\n",
    "axes.set_ylabel('mse')\n",
    "axes.set_title('mse with different n_iters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (五)步骤五"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5711885067465754,\n",
       " 0.5730638534401142,\n",
       " 0.6009722832399678,\n",
       " 0.5858428693245122,\n",
       " 0.5854269632262313,\n",
       " 0.6116584098337158,\n",
       " 0.8188827629569787,\n",
       " 2.1526951288881047,\n",
       " 1.4369978574664528]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning_ratio_list=[0.001,0.005,0.01,0.05,0.1,0.3,0.5]\n",
    "learning_ratio_list=(0.001,0.002,0.004,0.005,0.008,0.01,0.05,0.1,0.11)\n",
    "gd_mses=[]\n",
    "sgd_mses=[]\n",
    "# gd_mses.append(compute_mse(x_train,y_train,W_init))    \n",
    "# sgd_mses.append(compute_mse(x_train,y_train,W_init))\n",
    "\n",
    "for l_r in learning_ratio_list:\n",
    "    w_gd,mses = fit_gd(x_train,y_train,theta=W_init, learning_ratio=l_r)\n",
    "    w_sgd,smses = fit_sgd(x_train,y_train,theta=W_init,learning_ratio=l_r)\n",
    "    gd_mses.append(compute_mse(x_train,y_train,w_gd))    \n",
    "    sgd_mses.append(compute_mse(x_train,y_train,w_sgd))\n",
    "# gd_mses\n",
    "sgd_mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ef73ca6d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ef73ca9d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'n_iters')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'mse with different n_iters')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots()\n",
    "axes.plot(learning_ratio_list, gd_mses, 'r')\n",
    "axes.plot(learning_ratio_list, sgd_mses, 'b')\n",
    "axes.set_xlabel('n_iters')\n",
    "axes.set_ylabel('mse')\n",
    "axes.set_title('mse with different n_iters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验要求我们对于批量梯度下降和随机梯度下降，采用不同的学习率并进行MSE曲线展示，分析选择最佳的学习率。我选取了(0.001,0.002,0.004,0.005,0.008,0.01,0.05,0.1,0.11)，若学习率太高的话，如上图所示，红色的是随机梯度下降，绿色的是批量梯度下降，当学习率到达一定数值时，随机梯度下降的mse会出现非常明显的抖动。\n",
    "\n",
    "故随机梯度下降更适合低学习率，从图中看，批量梯度下降高低学习率都适用，但在实际应用中，不能一味使用批量梯度下降，当数据量很大时，批量梯度下降的时间开销会非常大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 二、中级要求\n",
    "探究回归模型在机器学习和统计学上的差异。\n",
    "\n",
    "* 回归模型在机器学习领域和统计学领域中都十分常用，而且使用方法也相似，但其实际的含义具有本质的区别。我们希望同学们从回归模型的角度更加充分地理解机器学习和统计学的区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验的线性回归是一种统计学方法，我们使用机器学习来构建模型。\n",
    "\n",
    "在构建机器学习的模型过程中，我们需要将数据集分为训练集和测试集两个数据子集，并对模型进行一定的“训练”。此外，在我们使用测试集对模型测试前，我们并不知道这个模型的性能。\n",
    "\n",
    "\n",
    "我认为：\n",
    "\n",
    "* 机器学习的重点在于预测，即获得基于测试数据集的最优输出(如使用各种损失函数进行衡量)，从而模型性能达到最优。\n",
    "\n",
    "* 统计模型的重点在于刻画已有数据与结果变量之间的关系，而不是对未来的数据进行预测。该过程被称为统计推断过程，而非预测过程。\n",
    "\n",
    "衡量标准：\n",
    "* 机器学习:测试集的预测准确度\n",
    "* 统计模型:显著性检验，置信区间等\n",
    "\n",
    "部分参考：[读懂统计学与机器学习的本质区别](https://blog.csdn.net/eNohtZvQiJxo00aTz3y8/article/details/89879697)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、高级要求\n",
    "编程实现岭回归算法，求解训练样本的岭回归模型，平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法均可）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 岭回归：\n",
    " 实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法均可）\n",
    "# 解析法\n",
    "def weights(x,y,lam=0.2):\n",
    "    x_mat= np.mat(x)\n",
    "    y_mat =np.mat(y)\n",
    "    xtx=x_mat.T*x_mat\n",
    "    rxtx = xtx+lam*np.eye(x_mat.shape[1])\n",
    "    if np.linalg.det(rxtx) == 0.0:\n",
    "        print(\"This matrix cannot do inverse, plz change lambda.\")\n",
    "        return \n",
    "\n",
    "    theta = rxtx.I*x_mat.T*y_mat\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均训练mse:\n",
      "0.5678390774407152\n",
      "平均测试mse:\n",
      "0.5462387164993198\n"
     ]
    }
   ],
   "source": [
    "w_t = weights(x_train,y_train)\n",
    "# !!! 岭系数\n",
    "w=np.asarray(w_t)\n",
    "print(\"平均训练mse:\")\n",
    "print(compute_mse(x_train,y_train,w))\n",
    "print(\"平均测试mse:\")\n",
    "print(compute_mse(test_x,test_y,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5462547424452671,\n",
       " 0.5462539344198891,\n",
       " 0.5462531271034841,\n",
       " 0.5462515145970889,\n",
       " 0.5462482980864349,\n",
       " 0.546246694080167,\n",
       " 0.5462450929052668,\n",
       " 0.5462418990455624,\n",
       " 0.5462387164993198,\n",
       " 0.5462347542139077,\n",
       " 0.5462308095777458,\n",
       " 0.5462268825753205,\n",
       " 0.5462229731911606,\n",
       " 0.5462190814098385,\n",
       " 0.5462152072159692,\n",
       " 0.5462113505942108]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lams = [0,0.01,0.02,0.04,0.08,0.10,0.12,0.16,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55]\n",
    "\n",
    "# lams\n",
    "train_mses =[]\n",
    "test_mses = []\n",
    "for lam in lams:\n",
    "    w_t = weights(x_train,y_train,lam)\n",
    "    w=np.asarray(w_t)\n",
    "    train_mses.append(compute_mse(x_train,y_train,w))\n",
    "    test_mses.append(compute_mse(test_x,test_y,w))\n",
    "\n",
    "test_mses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本实验中，改变lam值，mse并没有很大的改变，我们可以对lam做进一步的探究。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
